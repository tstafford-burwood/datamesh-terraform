timeout: 3600s

steps:

# SECURE DATA DATA OPS PROJECT

- id: "data-ops project - init"
  name: hashicorp/terraform:${_TAG}
  dir: 'environment/foundation/data-ops-project'
  args: [
  'init',
  '-backend-config=bucket=${_BUCKET}',
  '-backend-config=prefix=${_PREFIX}/data-ops-project'
  ]

- id: Terraform Format
  name: 'hashicorp/terraform:${_TAG}'
  dir: 'environment/foundation/data-ops-project'
  args: ['fmt',
    '-check'
    ]

- id: Terraform Validate
  name: 'hashicorp/terraform:${_TAG}'
  dir: 'environment/foundation/data-ops-project'
  args: ['validate',
    '-no-color'
    ]

- id: "data-ops project - first plan"
  name: hashicorp/terraform:${_TAG}
  dir: 'environment/foundation/data-ops-project'
  args: [
  'plan',
  '-var-file=env/${_TFVARS_FILE}.tfvars',
  '-var=terraform_foundation_state_prefix=${_PREFIX}',
  '-target=module.secure-staging-project'
  ]

- id: "data-ops project - first apply"
  name: hashicorp/terraform:${_TAG}
  dir: 'environment/foundation/data-ops-project'
  args: [
  'apply',
  '-var-file=env/${_TFVARS_FILE}.tfvars',
  '-var=terraform_foundation_state_prefix=${_PREFIX}',
  '-target=module.secure-staging-project',
  '-auto-approve'
  ]

# Get data-ops project ID in order to enable the DLP API service agent

- id: "data-ops project - output"
  name: hashicorp/terraform:${_TAG}
  dir: 'environment/foundation/data-ops-project'
  entrypoint: /bin/sh
  args: [
  '-c',
  'terraform output staging_project_id > _STAGING_PROJECT_ID && cat _STAGING_PROJECT_ID'
  ]


# Need to enable here in order to perform IAM role assignments

- id: "data-ops project - enable DLP API service agent"
  name: gcr.io/cloud-builders/gcloud
  dir: 'environment/foundation/data-ops-project'
  entrypoint: "bash"
  args:
    - "-c"
    - |
        RESPONSE=$(curl -i --request POST \
        "https://dlp.googleapis.com/v2/projects/$(cat _STAGING_PROJECT_ID)/locations/us-central1/content:inspect" \
        --header "X-Goog-User-Project: $(cat _STAGING_PROJECT_ID)" \
        --header "Authorization: Bearer $(gcloud auth print-access-token)" \
        --header 'Accept: application/json' \
        --header 'Content-Type: application/json' \
        --data '{"item":{"value":"google@google.com"}}' \
        --compressed) \
    - echo "$$RESPONSE"

# Need to copy json file w/ BQ table definition for GCS Events from a sub-directory into the data-ops project directory

- id: "data-ops project - copy table_schema_gcs_events.json"
  name: gcr.io/cloud-builders/gcloud
  dir: 'environment/foundation/data-ops-project/bigquery-table-schema'
  entrypoint: /bin/sh
  args: [
  '-c',
  'cp table_schema_gcs_events.json /workspace/environment/foundation/data-ops-project'
  ]

# The following steps provision everything else.

- id: "data-ops project - second plan"
  name: hashicorp/terraform:${_TAG}
  dir: 'environment/foundation/data-ops-project'
  args: [
  'plan',
  '-var=terraform_foundation_state_prefix=${_PREFIX}',
  '-var-file=env/${_TFVARS_FILE}.tfvars'
  ]

- id: "data-ops project - second apply"
  name: hashicorp/terraform:${_TAG}
  dir: 'environment/foundation/data-ops-project'
  args: [
  'apply',
  '-var=terraform_foundation_state_prefix=${_PREFIX}',
  '-var-file=env/${_TFVARS_FILE}.tfvars',
  '-auto-approve'
  ]
